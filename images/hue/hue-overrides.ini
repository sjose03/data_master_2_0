# Lightweight Hue configuration file
# ==================================

[desktop]

  # Set this to a random string, the longer the better.
  secret_key=kasdlfjknasdfl3hbaksk3bwkasdfkasdfba23asdf

  # Webserver listens on this address and port
  http_host=0.0.0.0
  http_port=8888

  # Time zone name
  time_zone=America/Los_Angeles

  # Enable or disable debug mode.
  django_debug_mode=false

  # Enable or disable backtrace for server error
  http_500_debug_mode=false

  app_blacklist=search,hbase,security

  # Configuration options for specifying the Desktop Database. For more info,
  # see http://docs.djangoproject.com/en/1.11/ref/settings/#database-engine
  # ------------------------------------------------------------------------
  [[database]]
    # Database engine is typically one of:
    # postgresql_psycopg2, mysql, sqlite3 or oracle.
    #
    # Note that for sqlite3, 'name', below is a path to the filename. For other backends, it is the database name
    # Note for Oracle, options={"threaded":true} must be set in order to avoid crashes.
    # Note for Oracle, you can use the Oracle Service Name by setting "host=" and "port=" and then "name=<host>:<port>/<service_name>".
    # Note for MariaDB use the 'mysql' engine.

    engine=postgresql_psycopg2
    host=postgres
    port=5432
    user=hue
    password=hue
    name=hue


[dashboard]

  # Activate the SQL Dashboard (beta).
  has_sql_enabled=true


[hadoop]

  # Configuration for HDFS NameNode
  # ------------------------------------------------------------------------
  [[hdfs_clusters]]
    # HA support by using HttpFs

    [[[default]]]
      # Enter the filesystem uri
      #fs_defaultfs=hdfs://localhost:8020

      # Use WebHdfs/HttpFs as the communication mechanism.
      # Domain should be the NameNode or HttpFs host.
      # Default port is 14000 for HttpFs.
      webhdfs_url=http://hadoop_hive:9870/webhdfs/v1

  # Configuration for YARN (MR2)
  # ------------------------------------------------------------------------
  [[yarn_clusters]]

    [[[default]]]
      # Enter the host on which you are running the ResourceManager
      resourcemanager_host=http://hadoop_hive

      # The port where the ResourceManager IPC listens on
      resourcemanager_port=8032

      # URL of the ResourceManager API
      resourcemanager_api_url=http://hadoop_hive:8088

      # URL of the ProxyServer API
      proxy_api_url=http://hadoop_hive:8088

      # URL of the HistoryServer API
    ;   history_server_api_url=http://historyserver:8188

      # URL of the Spark History Server
      ## spark_history_server_url=http://localhost:18088


###########################################################################
# Settings to configure Beeswax with Hive
###########################################################################

[beeswax]

  # Host where HiveServer2 is running.
  # If Kerberos security is enabled, use fully-qualified domain name (FQDN).
  hive_server_host=hadoop_hive
  #jdbc:hive2://hive-server

  # Port where HiveServer2 Thrift server runs on.
  hive_server_port=10000

  #thrift_version=7



###########################################################################
# Settings to configure the Spark application.
###########################################################################

[spark]
  # The Livy Server URL.
  ## livy_server_url=http://localhost:8998

  # Configure Livy to start in local 'process' mode, or 'yarn' workers.
  ## livy_server_session_kind=yarn

  # Whether Livy requires client to perform Kerberos authentication.
  ## security_enabled=false

  # Host of the Sql Server
  ## sql_server_host=localhost

  # Port of the Sql Server
  ## sql_server_port=10000

  # Choose whether Hue should validate certificates received from the server.
  ## ssl_cert_ca_verify=true



[libzookeeper]
  # ZooKeeper ensemble. Comma separated list of Host/Port.
  # e.g. localhost:2181,localhost:2182,localhost:2183
  ## ensemble=localhost:2181


###########################################################################
# Settings to configure Kafka
###########################################################################

[kafka]

  [[kafka]]
    # Enable the Kafka integration.
    ## is_enabled=false

    # Base URL of Kafka REST API.
    ## api_url=http://localhost:8082


###########################################################################
# Settings to configure Metadata
###########################################################################

[metadata]

  [[navigator]]
    # Navigator API URL (without version suffix).
    ## api_url=http://localhost:7187/api

    # Which authentication to use: CM or external via LDAP or SAML.
    ## navmetadataserver_auth_type=CMDB

    # Username of the CM user used for authentication.
    ## navmetadataserver_cmdb_user=hue
    # CM password of the user used for authentication.
    ## navmetadataserver_cmdb_password=
    # Execute this script to produce the CM password. This will be used when the plain password is not set.
    # navmetadataserver_cmdb_password_script=